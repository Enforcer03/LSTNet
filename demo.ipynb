{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from LSTNet.lstnet_util import GetArguments, LSTNetInit\n",
    "from LSTNet.lstnet_model import PreSkipTrans, PostSkipTrans, PreARTrans, PostARTrans, LSTNetModel, ModelCompile\n",
    "import subprocess\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "class FetchStocks():\n",
    "    def __init__(self,\n",
    "                 period=\"1000d\",\n",
    "                 tickers=['AAPL', 'GOOGL', 'AMZN', 'MSFT', 'JPM', 'V', 'JNJ', 'PG', 'XOM', 'T', 'BAC', 'WMT', 'INTC', 'PFE',\n",
    "           'VZ', 'KO', 'TSLA', 'MRK', 'DIS', 'UNH', 'HD', 'ADBE', 'CMCSA', 'PEP', 'CSCO', 'NVDA', 'NFLX',\n",
    "           'ABT', 'NKE', 'CVX', 'ACN', 'TMUS', 'BMY', 'LLY', 'TMO', 'IBM', 'MCD', 'ORCL', 'UPS', 'MDT', 'COST',\n",
    "           'PM', 'AVGO', 'SAP', 'HON', 'NEE', 'TXN', 'MO'],\n",
    "           save_files=True\n",
    "           ):\n",
    "        self.csv_path=\"LSTNet\\data\\large_portfolio.csv\"\n",
    "        self.txt_path=\"LSTNet\\data\\large_portfolio.txt\"\n",
    "        self.tickers=tickers\n",
    "        self.period=period\n",
    "        self.downloaded_data = yf.download(self.tickers, period=self.period,group_by='ticker', auto_adjust=True)\n",
    "        open_prices = pd.DataFrame({ticker: self.downloaded_data[ticker]['Open'] for ticker in self.tickers})\n",
    "        self.df=open_prices\n",
    "        if save_files==True :\n",
    "            open_prices.to_csv(\"LSTNet\\data\\large_portfolio.csv\")\n",
    "            np.savetxt(\"LSTNet\\data\\large_portfolio.txt\", np.array(open_prices), delimiter=',')\n",
    "\n",
    "\n",
    "\n",
    "class LSTNetModel(FetchStocks):\n",
    "    def __init__ (self,\n",
    "                data_path=\"data\\large_portfolio.txt\",\n",
    "                horizon=1,\n",
    "                save_name=\"large_portfolio\",\n",
    "                window=7,\n",
    "                validpercent=0.40,\n",
    "                batchsize=16,\n",
    "                skip=7,\n",
    "                epochs=100,\n",
    "                cnn_kernel=6,\n",
    "                learning_rate=0.001,\n",
    "                dropout=0.2,\n",
    "                highway=7,\n",
    "                GRUUnits=100,\n",
    "                SkipGRUUnits=5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_path=data_path\n",
    "        self.horizon=horizon\n",
    "        self.save_name=save_name\n",
    "        self.window=window\n",
    "        self.validpercent=validpercent\n",
    "        self.batchsize=batchsize\n",
    "        self.skip=skip\n",
    "        self.epochs=epochs\n",
    "        self.cnn_kernel=cnn_kernel\n",
    "        self.learning_rate=learning_rate\n",
    "        self.dropout=dropout\n",
    "        self.highway=highway\n",
    "        self.GRUUnits=GRUUnits\n",
    "        self.SkipGRUUnits=SkipGRUUnits\n",
    "    \n",
    "    def train_model(self):\n",
    "        print(\"training...\")\n",
    "        os.chdir(\"LSTNet\")\n",
    "        command = f'python main.py --data={self.data_path} --horizon={self.horizon} --save=\"save/{self.save_name}_horizon{self.horizon}_window{self.window}_skip{self.skip}\" --test --savehistory --logfilename=\"log/lstnet\" --debuglevel=20 --predict=\"all\" --plot --save-plot=\"save/{self.save_name}_horizon{self.horizon}_window{self.window}_skip{self.skip}_plots\" --window={self.window} --validpercent={self.validpercent} --batchsize={self.batchsize} --skip={self.skip} --epochs={self.epochs} --CNNKernel={self.cnn_kernel} --lr={self.learning_rate} --dropout={self.dropout} --highway={self.highway} --GRUUnits={self.GRUUnits} --SkipGRUUnits={self.SkipGRUUnits}' \n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        output, error = process.communicate()\n",
    "\n",
    "        if process.returncode == 0:\n",
    "            print(output.decode())\n",
    "        else:\n",
    "            print(\"Error:\", error.decode())\n",
    "        print(\"model saved\")\n",
    "        print(f'Outputs can be found at: LSTNet/save/{self.save_name}_horizon{self.horizon}_window{self.window}_skip{self.skip}')\n",
    "    \n",
    "    def get_trained_model(self):\n",
    "        custom_objects = {\"PreSkipTrans\": PreSkipTrans,\n",
    "                  \"PostSkipTrans\": PostSkipTrans,\n",
    "                  \"PreARTrans\": PreARTrans,\n",
    "                  \"PostARTrans\": PostARTrans,\n",
    "                  }\n",
    "\n",
    "        json_file = open(f'save\\{self.save_name}_horizon{self.horizon}_window{self.window}_skip{self.skip}.json', 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "\n",
    "        loaded_model = model_from_json(loaded_model_json, custom_objects=custom_objects)\n",
    "        loaded_model.load_weights(f'save\\{self.save_name}_horizon{self.horizon}_window{self.window}_skip{self.skip}.h5')\n",
    "\n",
    "        model = loaded_model\n",
    "        return model\n",
    "\n",
    "class LSTNetIteratedModel(LSTNetModel, FetchStocks):\n",
    "    def __init__(self,\n",
    "                 forecast_steps,\n",
    "                 n_series,\n",
    "                 csv_path,\n",
    "                 save_forecast_json=True\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.forecast_steps=forecast_steps\n",
    "        self.timesteps=self.window\n",
    "        self.series=np.array(pd.read_csv(csv_path))[:,1:]\n",
    "        self.json=save_forecast_json\n",
    " \n",
    "    def get_forecast(self):\n",
    "        model=self.get_trained_model()\n",
    "        series=self.series\n",
    "        time_steps=self.window\n",
    "        forecast_steps=self.forecast_steps\n",
    "        last_batch=series[-time_steps:,:]\n",
    "        forecast=[]\n",
    "        for step in range(forecast_steps):\n",
    "            pred=model.predict(np.array(last_batch, dtype='float32').reshape(1,time_steps,series.shape[1]))\n",
    "            forecast.append(pred)\n",
    "            last_batch=np.append(last_batch[1:,:],pred, axis=0)\n",
    "        forecast=np.array(forecast)\n",
    "        \n",
    "        return forecast\n",
    "\n",
    "    def plot_lstnet_forecast(self, series_index=24):\n",
    "        model=self.get_trained_model()\n",
    "        series=self.series\n",
    "        time_steps=self.window\n",
    "        forecast=self.get_forecast()\n",
    "        forecast_df=pd.DataFrame(forecast.reshape(self.forecast_steps,series.shape[1]))\n",
    "        forecast_df.columns=self.tickers \n",
    "\n",
    "        series_df=pd.DataFrame(series)\n",
    "        series_df.columns=self.tickers\n",
    "        cumulative_df=pd.concat([series_df,forecast_df], axis=0)\n",
    "        cumulative_df=pd.DataFrame(np.array(cumulative_df))\n",
    "        cumulative_df.iloc[-(100+len(forecast_df)):-len(forecast_df),series_index].plot(color='blue')\n",
    "        cumulative_df.iloc[-len(forecast_df):,series_index].plot(color='red')\n",
    "        output_df=cumulative_df.iloc[-55:,:]\n",
    "    \n",
    "        if self.json==True:\n",
    "            json_data = output_df.to_json(orient='index')\n",
    "\n",
    "            with open('LargePortfolioLSTNet_forecast.json', 'w') as f:\n",
    "                f.write(json_data)\n",
    "            print('JSON data saved to', 'LargePortfolioLSTNet_forecast.json')\n",
    "\n",
    "        plt.legend()\n",
    "        title_ticker=self.tickers[series_index]\n",
    "        plt.title(title_ticker)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  48 of 48 completed\n"
     ]
    }
   ],
   "source": [
    "fetcher=FetchStocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>JPM</th>\n",
       "      <th>V</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>PG</th>\n",
       "      <th>XOM</th>\n",
       "      <th>T</th>\n",
       "      <th>...</th>\n",
       "      <th>UPS</th>\n",
       "      <th>MDT</th>\n",
       "      <th>COST</th>\n",
       "      <th>PM</th>\n",
       "      <th>AVGO</th>\n",
       "      <th>SAP</th>\n",
       "      <th>HON</th>\n",
       "      <th>NEE</th>\n",
       "      <th>TXN</th>\n",
       "      <th>MO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-02</th>\n",
       "      <td>49.852464</td>\n",
       "      <td>60.150002</td>\n",
       "      <td>92.253502</td>\n",
       "      <td>132.726069</td>\n",
       "      <td>99.535635</td>\n",
       "      <td>173.290134</td>\n",
       "      <td>117.616369</td>\n",
       "      <td>105.537941</td>\n",
       "      <td>58.500793</td>\n",
       "      <td>18.548447</td>\n",
       "      <td>...</td>\n",
       "      <td>103.342073</td>\n",
       "      <td>92.191289</td>\n",
       "      <td>259.157653</td>\n",
       "      <td>66.082457</td>\n",
       "      <td>245.881555</td>\n",
       "      <td>113.594180</td>\n",
       "      <td>155.755031</td>\n",
       "      <td>48.490001</td>\n",
       "      <td>111.197934</td>\n",
       "      <td>35.109502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-05</th>\n",
       "      <td>48.023592</td>\n",
       "      <td>58.648499</td>\n",
       "      <td>88.511002</td>\n",
       "      <td>128.122143</td>\n",
       "      <td>98.109903</td>\n",
       "      <td>167.458644</td>\n",
       "      <td>117.661317</td>\n",
       "      <td>105.157497</td>\n",
       "      <td>57.026381</td>\n",
       "      <td>18.493569</td>\n",
       "      <td>...</td>\n",
       "      <td>102.305576</td>\n",
       "      <td>90.646057</td>\n",
       "      <td>255.180009</td>\n",
       "      <td>66.777622</td>\n",
       "      <td>237.059915</td>\n",
       "      <td>111.230912</td>\n",
       "      <td>152.333540</td>\n",
       "      <td>48.591060</td>\n",
       "      <td>107.614372</td>\n",
       "      <td>34.628748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>47.616106</td>\n",
       "      <td>58.276001</td>\n",
       "      <td>89.611504</td>\n",
       "      <td>128.602686</td>\n",
       "      <td>97.454601</td>\n",
       "      <td>167.244454</td>\n",
       "      <td>117.148988</td>\n",
       "      <td>102.947291</td>\n",
       "      <td>56.631598</td>\n",
       "      <td>18.389298</td>\n",
       "      <td>...</td>\n",
       "      <td>102.420742</td>\n",
       "      <td>90.365907</td>\n",
       "      <td>251.759912</td>\n",
       "      <td>64.819942</td>\n",
       "      <td>235.473411</td>\n",
       "      <td>109.303241</td>\n",
       "      <td>150.664314</td>\n",
       "      <td>47.805551</td>\n",
       "      <td>106.838097</td>\n",
       "      <td>34.169856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-07</th>\n",
       "      <td>47.397804</td>\n",
       "      <td>57.889999</td>\n",
       "      <td>88.699501</td>\n",
       "      <td>128.593049</td>\n",
       "      <td>95.639237</td>\n",
       "      <td>166.962145</td>\n",
       "      <td>116.268176</td>\n",
       "      <td>103.037848</td>\n",
       "      <td>56.285174</td>\n",
       "      <td>18.438689</td>\n",
       "      <td>...</td>\n",
       "      <td>100.675463</td>\n",
       "      <td>90.691226</td>\n",
       "      <td>253.375474</td>\n",
       "      <td>64.212641</td>\n",
       "      <td>230.156007</td>\n",
       "      <td>110.294881</td>\n",
       "      <td>150.286219</td>\n",
       "      <td>48.552020</td>\n",
       "      <td>105.872251</td>\n",
       "      <td>33.441438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-08</th>\n",
       "      <td>48.559644</td>\n",
       "      <td>59.321499</td>\n",
       "      <td>90.300003</td>\n",
       "      <td>131.293939</td>\n",
       "      <td>96.569054</td>\n",
       "      <td>172.764437</td>\n",
       "      <td>117.724224</td>\n",
       "      <td>104.641170</td>\n",
       "      <td>57.082782</td>\n",
       "      <td>18.795390</td>\n",
       "      <td>...</td>\n",
       "      <td>103.244612</td>\n",
       "      <td>91.748518</td>\n",
       "      <td>257.967183</td>\n",
       "      <td>65.067629</td>\n",
       "      <td>235.691328</td>\n",
       "      <td>111.944533</td>\n",
       "      <td>151.789421</td>\n",
       "      <td>48.972323</td>\n",
       "      <td>110.105700</td>\n",
       "      <td>33.667246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-18</th>\n",
       "      <td>193.350006</td>\n",
       "      <td>124.599998</td>\n",
       "      <td>132.710007</td>\n",
       "      <td>345.829987</td>\n",
       "      <td>153.380005</td>\n",
       "      <td>243.100006</td>\n",
       "      <td>159.070007</td>\n",
       "      <td>147.709328</td>\n",
       "      <td>100.919998</td>\n",
       "      <td>13.530000</td>\n",
       "      <td>...</td>\n",
       "      <td>182.820007</td>\n",
       "      <td>86.129997</td>\n",
       "      <td>552.669983</td>\n",
       "      <td>98.620003</td>\n",
       "      <td>905.979980</td>\n",
       "      <td>144.380005</td>\n",
       "      <td>206.699997</td>\n",
       "      <td>72.769997</td>\n",
       "      <td>182.440002</td>\n",
       "      <td>45.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-19</th>\n",
       "      <td>193.100006</td>\n",
       "      <td>124.599998</td>\n",
       "      <td>133.389999</td>\n",
       "      <td>361.750000</td>\n",
       "      <td>152.750000</td>\n",
       "      <td>241.250000</td>\n",
       "      <td>157.910004</td>\n",
       "      <td>148.613642</td>\n",
       "      <td>101.050003</td>\n",
       "      <td>14.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>184.600006</td>\n",
       "      <td>86.349998</td>\n",
       "      <td>554.479980</td>\n",
       "      <td>98.010002</td>\n",
       "      <td>897.270020</td>\n",
       "      <td>143.630005</td>\n",
       "      <td>203.850006</td>\n",
       "      <td>72.360001</td>\n",
       "      <td>183.589996</td>\n",
       "      <td>45.599998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-20</th>\n",
       "      <td>195.089996</td>\n",
       "      <td>121.419998</td>\n",
       "      <td>134.070007</td>\n",
       "      <td>353.570007</td>\n",
       "      <td>154.529999</td>\n",
       "      <td>241.160004</td>\n",
       "      <td>161.940002</td>\n",
       "      <td>149.550003</td>\n",
       "      <td>102.540001</td>\n",
       "      <td>14.590000</td>\n",
       "      <td>...</td>\n",
       "      <td>186.630005</td>\n",
       "      <td>87.250000</td>\n",
       "      <td>553.809998</td>\n",
       "      <td>99.779999</td>\n",
       "      <td>892.539978</td>\n",
       "      <td>140.860001</td>\n",
       "      <td>206.149994</td>\n",
       "      <td>72.099998</td>\n",
       "      <td>180.649994</td>\n",
       "      <td>45.689999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-21</th>\n",
       "      <td>194.100006</td>\n",
       "      <td>120.620003</td>\n",
       "      <td>131.339996</td>\n",
       "      <td>349.149994</td>\n",
       "      <td>155.800003</td>\n",
       "      <td>239.740005</td>\n",
       "      <td>168.179993</td>\n",
       "      <td>151.149994</td>\n",
       "      <td>104.160004</td>\n",
       "      <td>14.610000</td>\n",
       "      <td>...</td>\n",
       "      <td>186.910004</td>\n",
       "      <td>89.699997</td>\n",
       "      <td>559.169983</td>\n",
       "      <td>98.540001</td>\n",
       "      <td>904.489990</td>\n",
       "      <td>135.750000</td>\n",
       "      <td>208.309998</td>\n",
       "      <td>74.419998</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>45.669998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-24</th>\n",
       "      <td>193.410004</td>\n",
       "      <td>121.660004</td>\n",
       "      <td>130.309998</td>\n",
       "      <td>345.850006</td>\n",
       "      <td>154.970001</td>\n",
       "      <td>239.679993</td>\n",
       "      <td>171.500000</td>\n",
       "      <td>152.839996</td>\n",
       "      <td>104.360001</td>\n",
       "      <td>14.780000</td>\n",
       "      <td>...</td>\n",
       "      <td>185.860001</td>\n",
       "      <td>89.089996</td>\n",
       "      <td>558.000000</td>\n",
       "      <td>97.540001</td>\n",
       "      <td>900.799988</td>\n",
       "      <td>133.520004</td>\n",
       "      <td>208.669998</td>\n",
       "      <td>75.879997</td>\n",
       "      <td>184.580002</td>\n",
       "      <td>45.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAPL       GOOGL        AMZN        MSFT         JPM  \\\n",
       "Date                                                                     \n",
       "2019-08-02   49.852464   60.150002   92.253502  132.726069   99.535635   \n",
       "2019-08-05   48.023592   58.648499   88.511002  128.122143   98.109903   \n",
       "2019-08-06   47.616106   58.276001   89.611504  128.602686   97.454601   \n",
       "2019-08-07   47.397804   57.889999   88.699501  128.593049   95.639237   \n",
       "2019-08-08   48.559644   59.321499   90.300003  131.293939   96.569054   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-07-18  193.350006  124.599998  132.710007  345.829987  153.380005   \n",
       "2023-07-19  193.100006  124.599998  133.389999  361.750000  152.750000   \n",
       "2023-07-20  195.089996  121.419998  134.070007  353.570007  154.529999   \n",
       "2023-07-21  194.100006  120.620003  131.339996  349.149994  155.800003   \n",
       "2023-07-24  193.410004  121.660004  130.309998  345.850006  154.970001   \n",
       "\n",
       "                     V         JNJ          PG         XOM          T  ...  \\\n",
       "Date                                                                   ...   \n",
       "2019-08-02  173.290134  117.616369  105.537941   58.500793  18.548447  ...   \n",
       "2019-08-05  167.458644  117.661317  105.157497   57.026381  18.493569  ...   \n",
       "2019-08-06  167.244454  117.148988  102.947291   56.631598  18.389298  ...   \n",
       "2019-08-07  166.962145  116.268176  103.037848   56.285174  18.438689  ...   \n",
       "2019-08-08  172.764437  117.724224  104.641170   57.082782  18.795390  ...   \n",
       "...                ...         ...         ...         ...        ...  ...   \n",
       "2023-07-18  243.100006  159.070007  147.709328  100.919998  13.530000  ...   \n",
       "2023-07-19  241.250000  157.910004  148.613642  101.050003  14.320000  ...   \n",
       "2023-07-20  241.160004  161.940002  149.550003  102.540001  14.590000  ...   \n",
       "2023-07-21  239.740005  168.179993  151.149994  104.160004  14.610000  ...   \n",
       "2023-07-24  239.679993  171.500000  152.839996  104.360001  14.780000  ...   \n",
       "\n",
       "                   UPS        MDT        COST         PM        AVGO  \\\n",
       "Date                                                                   \n",
       "2019-08-02  103.342073  92.191289  259.157653  66.082457  245.881555   \n",
       "2019-08-05  102.305576  90.646057  255.180009  66.777622  237.059915   \n",
       "2019-08-06  102.420742  90.365907  251.759912  64.819942  235.473411   \n",
       "2019-08-07  100.675463  90.691226  253.375474  64.212641  230.156007   \n",
       "2019-08-08  103.244612  91.748518  257.967183  65.067629  235.691328   \n",
       "...                ...        ...         ...        ...         ...   \n",
       "2023-07-18  182.820007  86.129997  552.669983  98.620003  905.979980   \n",
       "2023-07-19  184.600006  86.349998  554.479980  98.010002  897.270020   \n",
       "2023-07-20  186.630005  87.250000  553.809998  99.779999  892.539978   \n",
       "2023-07-21  186.910004  89.699997  559.169983  98.540001  904.489990   \n",
       "2023-07-24  185.860001  89.089996  558.000000  97.540001  900.799988   \n",
       "\n",
       "                   SAP         HON        NEE         TXN         MO  \n",
       "Date                                                                  \n",
       "2019-08-02  113.594180  155.755031  48.490001  111.197934  35.109502  \n",
       "2019-08-05  111.230912  152.333540  48.591060  107.614372  34.628748  \n",
       "2019-08-06  109.303241  150.664314  47.805551  106.838097  34.169856  \n",
       "2019-08-07  110.294881  150.286219  48.552020  105.872251  33.441438  \n",
       "2019-08-08  111.944533  151.789421  48.972323  110.105700  33.667246  \n",
       "...                ...         ...        ...         ...        ...  \n",
       "2023-07-18  144.380005  206.699997  72.769997  182.440002  45.400002  \n",
       "2023-07-19  143.630005  203.850006  72.360001  183.589996  45.599998  \n",
       "2023-07-20  140.860001  206.149994  72.099998  180.649994  45.689999  \n",
       "2023-07-21  135.750000  208.309998  74.419998  182.000000  45.669998  \n",
       "2023-07-24  133.520004  208.669998  75.879997  184.580002  45.570000  \n",
       "\n",
       "[1000 rows x 48 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetcher.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  48 of 48 completed\n"
     ]
    }
   ],
   "source": [
    "csv_path=fetcher.csv_path\n",
    "lstnet_iterated=LSTNetIteratedModel(n_series=48,forecast_steps=15, csv_path=csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Epoch 1/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 3:42 - loss: 1.2713 - rse: 7.3417 - corr: 0.9458\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.8801 - rse: 5.6587 - corr: 0.6426  \n",
      "16/38 [===========>..................] - ETA: 0s - loss: 0.7492 - rse: 4.9753 - corr: 0.5668\n",
      "25/38 [==================>...........] - ETA: 0s - loss: 0.6267 - rse: 4.2048 - corr: 0.5079\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.5520 - rse: 3.7203 - corr: 0.5003\n",
      "38/38 [==============================] - 7s 35ms/step - loss: 0.5226 - rse: 3.4873 - corr: nan - val_loss: 0.2490 - val_rse: 2.3105 - val_corr: 0.2228\n",
      "Epoch 2/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.2516 - rse: 1.7729 - corr: 0.3571\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.2592 - rse: 1.7932 - corr: 0.4835\n",
      "18/38 [=============>................] - ETA: 0s - loss: 0.2476 - rse: 1.7165 - corr: 0.5027\n",
      "27/38 [====================>.........] - ETA: 0s - loss: 0.2318 - rse: 1.6045 - corr: 0.5250\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.2209 - rse: 1.5293 - corr: 0.5500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.2194 - rse: 1.5185 - corr: nan - val_loss: 0.2112 - val_rse: 1.8736 - val_corr: 0.2294\n",
      "Epoch 3/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.1653 - rse: 1.1443 - corr: 0.6340\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.1743 - rse: 1.1840 - corr: 0.6623\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.1693 - rse: 1.1616 - corr: 0.6488\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 0.1651 - rse: 1.1282 - corr: 0.6424\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.1618 - rse: 1.1147 - corr: 0.6506\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1609 - rse: 1.1119 - corr: nan - val_loss: 0.1922 - val_rse: 1.7615 - val_corr: 0.2155\n",
      "Epoch 4/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.1412 - rse: 1.0050 - corr: 0.6992\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.1356 - rse: 0.9299 - corr: 0.6760\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.1297 - rse: 0.8905 - corr: 0.6806\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 0.1245 - rse: 0.8566 - corr: 0.6909\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1198 - rse: 0.8275 - corr: 0.6949\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1197 - rse: 0.8257 - corr: nan - val_loss: 0.1843 - val_rse: 1.6110 - val_corr: 0.2112\n",
      "Epoch 5/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.1008 - rse: 0.7090 - corr: 0.8002\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.1125 - rse: 0.7700 - corr: 0.7472\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.1134 - rse: 0.7779 - corr: 0.7523\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 0.1103 - rse: 0.7550 - corr: 0.7595\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.1065 - rse: 0.7301 - corr: 0.7576\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1064 - rse: 0.7204 - corr: nan - val_loss: 0.2319 - val_rse: 1.9087 - val_corr: 0.2141\n",
      "Epoch 6/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.1613 - rse: 1.0932 - corr: 0.8093\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.1265 - rse: 0.8544 - corr: 0.7646\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.1163 - rse: 0.7900 - corr: 0.7742\n",
      "27/38 [====================>.........] - ETA: 0s - loss: 0.1076 - rse: 0.7341 - corr: 0.7749\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.1011 - rse: 0.6936 - corr: 0.7799\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.1003 - rse: 0.6875 - corr: nan - val_loss: 0.1626 - val_rse: 1.4038 - val_corr: 0.2109\n",
      "Epoch 7/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0712 - rse: 0.5280 - corr: 0.8338\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0806 - rse: 0.5606 - corr: 0.8074\n",
      "18/38 [=============>................] - ETA: 0s - loss: 0.0780 - rse: 0.5416 - corr: 0.8149\n",
      "27/38 [====================>.........] - ETA: 0s - loss: 0.0756 - rse: 0.5251 - corr: 0.8156\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.0752 - rse: 0.5231 - corr: 0.8186\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0749 - rse: 0.5220 - corr: nan - val_loss: 0.1637 - val_rse: 1.3963 - val_corr: 0.2084\n",
      "Epoch 8/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0761 - rse: 0.5092 - corr: 0.8922\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0699 - rse: 0.4850 - corr: 0.8385\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0669 - rse: 0.4678 - corr: 0.8427\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 0.0647 - rse: 0.4530 - corr: 0.8474\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0639 - rse: 0.4476 - corr: 0.8456\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0639 - rse: 0.4462 - corr: nan - val_loss: 0.1480 - val_rse: 1.2561 - val_corr: 0.2060\n",
      "Epoch 9/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0567 - rse: 0.4089 - corr: 0.8828\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0589 - rse: 0.4147 - corr: 0.8710\n",
      "17/38 [============>.................] - ETA: 0s - loss: 0.0591 - rse: 0.4159 - corr: 0.8697\n",
      "26/38 [===================>..........] - ETA: 0s - loss: 0.0582 - rse: 0.4133 - corr: 0.8659\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.0575 - rse: 0.4051 - corr: 0.8659\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0575 - rse: 0.4076 - corr: nan - val_loss: 0.1321 - val_rse: 1.1400 - val_corr: 0.2013\n",
      "Epoch 10/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0576 - rse: 0.4206 - corr: 0.8544\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0552 - rse: 0.3907 - corr: 0.8795\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0538 - rse: 0.3803 - corr: 0.8797\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 0.0521 - rse: 0.3682 - corr: 0.8799\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0517 - rse: 0.3648 - corr: 0.8804\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0517 - rse: 0.3666 - corr: nan - val_loss: 0.1281 - val_rse: 1.0829 - val_corr: 0.1997\n",
      "Epoch 11/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0480 - rse: 0.3556 - corr: 0.8792\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0490 - rse: 0.3519 - corr: 0.8756\n",
      "18/38 [=============>................] - ETA: 0s - loss: 0.0485 - rse: 0.3466 - corr: 0.8799\n",
      "27/38 [====================>.........] - ETA: 0s - loss: 0.0487 - rse: 0.3458 - corr: 0.8847\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.0484 - rse: 0.3432 - corr: 0.8861\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0480 - rse: 0.3404 - corr: nan - val_loss: 0.1116 - val_rse: 0.9711 - val_corr: 0.1992\n",
      "Epoch 12/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0477 - rse: 0.3344 - corr: 0.8907\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0518 - rse: 0.3613 - corr: 0.9010\n",
      "17/38 [============>.................] - ETA: 0s - loss: 0.0491 - rse: 0.3426 - corr: 0.9009\n",
      "26/38 [===================>..........] - ETA: 0s - loss: 0.0478 - rse: 0.3350 - corr: 0.8992\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0470 - rse: 0.3300 - corr: 0.9032\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0466 - rse: 0.3261 - corr: nan - val_loss: 0.1105 - val_rse: 0.9384 - val_corr: 0.1964\n",
      "Epoch 13/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0420 - rse: 0.2805 - corr: 0.9210\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0416 - rse: 0.2969 - corr: 0.9048\n",
      "18/38 [=============>................] - ETA: 0s - loss: 0.0411 - rse: 0.2940 - corr: 0.9038\n",
      "27/38 [====================>.........] - ETA: 0s - loss: 0.0406 - rse: 0.2918 - corr: 0.9076\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.0400 - rse: 0.2861 - corr: 0.9087\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0401 - rse: 0.2932 - corr: nan - val_loss: 0.1057 - val_rse: 0.9076 - val_corr: 0.1995\n",
      "Epoch 14/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0384 - rse: 0.2716 - corr: 0.9395\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0401 - rse: 0.2811 - corr: 0.9306\n",
      "18/38 [=============>................] - ETA: 0s - loss: 0.0392 - rse: 0.2774 - corr: 0.9182\n",
      "26/38 [===================>..........] - ETA: 0s - loss: 0.0388 - rse: 0.2766 - corr: 0.9192\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0384 - rse: 0.2745 - corr: 0.9198\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0382 - rse: 0.2754 - corr: nan - val_loss: 0.0909 - val_rse: 0.7867 - val_corr: 0.1960\n",
      "Epoch 15/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0391 - rse: 0.2784 - corr: 0.9397\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0392 - rse: 0.2795 - corr: 0.9169\n",
      "15/38 [==========>...................] - ETA: 0s - loss: 0.0377 - rse: 0.2729 - corr: 0.9212\n",
      "23/38 [=================>............] - ETA: 0s - loss: 0.0366 - rse: 0.2654 - corr: 0.9226\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0356 - rse: 0.2565 - corr: 0.9247\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0351 - rse: 0.2544 - corr: nan - val_loss: 0.0912 - val_rse: 0.7749 - val_corr: 0.1953\n",
      "Epoch 16/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0307 - rse: 0.2167 - corr: 0.9431\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0331 - rse: 0.2396 - corr: 0.9346\n",
      "18/38 [=============>................] - ETA: 0s - loss: 0.0336 - rse: 0.2428 - corr: 0.9311\n",
      "26/38 [===================>..........] - ETA: 0s - loss: 0.0341 - rse: 0.2459 - corr: 0.9312\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.0342 - rse: 0.2460 - corr: 0.9321\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0341 - rse: 0.2468 - corr: nan - val_loss: 0.0906 - val_rse: 0.7653 - val_corr: 0.1934\n",
      "Epoch 17/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0324 - rse: 0.2315 - corr: 0.9338\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0327 - rse: 0.2318 - corr: 0.9357\n",
      "17/38 [============>.................] - ETA: 0s - loss: 0.0324 - rse: 0.2315 - corr: 0.9344\n",
      "25/38 [==================>...........] - ETA: 0s - loss: 0.0332 - rse: 0.2368 - corr: 0.9345\n",
      "33/38 [=========================>....] - ETA: 0s - loss: 0.0332 - rse: 0.2374 - corr: 0.9332\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0327 - rse: 0.2363 - corr: nan - val_loss: 0.0767 - val_rse: 0.6673 - val_corr: 0.1919\n",
      "Epoch 18/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0343 - rse: 0.2531 - corr: 0.9074\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0321 - rse: 0.2320 - corr: 0.9330\n",
      "17/38 [============>.................] - ETA: 0s - loss: 0.0322 - rse: 0.2308 - corr: 0.9337\n",
      "25/38 [==================>...........] - ETA: 0s - loss: 0.0317 - rse: 0.2273 - corr: 0.9371\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0318 - rse: 0.2278 - corr: 0.9373\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0315 - rse: 0.2322 - corr: nan - val_loss: 0.0931 - val_rse: 0.7672 - val_corr: 0.1949\n",
      "Epoch 19/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0419 - rse: 0.2972 - corr: 0.9212\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0371 - rse: 0.2605 - corr: 0.9370\n",
      "18/38 [=============>................] - ETA: 0s - loss: 0.0335 - rse: 0.2367 - corr: 0.9406\n",
      "26/38 [===================>..........] - ETA: 0s - loss: 0.0327 - rse: 0.2321 - corr: 0.9399\n",
      "34/38 [=========================>....] - ETA: 0s - loss: 0.0317 - rse: 0.2265 - corr: 0.9402\n",
      "38/38 [==============================] - 0s 10ms/step - loss: 0.0315 - rse: 0.2244 - corr: nan - val_loss: 0.0740 - val_rse: 0.6487 - val_corr: 0.1968\n",
      "Epoch 20/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0295 - rse: 0.2069 - corr: 0.9570\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0295 - rse: 0.2109 - corr: 0.9459\n",
      "18/38 [=============>................] - ETA: 0s - loss: 0.0290 - rse: 0.2098 - corr: 0.9434\n",
      "27/38 [====================>.........] - ETA: 0s - loss: 0.0285 - rse: 0.2082 - corr: 0.9426\n",
      "35/38 [==========================>...] - ETA: 0s - loss: 0.0281 - rse: 0.2053 - corr: 0.9434\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0281 - rse: 0.2049 - corr: nan - val_loss: 0.0679 - val_rse: 0.5872 - val_corr: 0.1955\n",
      "Epoch 21/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0250 - rse: 0.1759 - corr: 0.9533\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0280 - rse: 0.2059 - corr: 0.9384\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0277 - rse: 0.2024 - corr: 0.9417\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0282 - rse: 0.2051 - corr: 0.9420\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0283 - rse: 0.2043 - corr: nan   \n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0283 - rse: 0.2043 - corr: nan - val_loss: 0.0754 - val_rse: 0.6353 - val_corr: 0.1900\n",
      "Epoch 22/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0353 - rse: 0.2336 - corr: 0.9400\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0306 - rse: 0.2187 - corr: 0.9491\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0308 - rse: 0.2204 - corr: 0.9436\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 0.0301 - rse: 0.2163 - corr: 0.9439\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0298 - rse: 0.2140 - corr: 0.9444\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0298 - rse: 0.2176 - corr: nan - val_loss: 0.0650 - val_rse: 0.5846 - val_corr: 0.1909\n",
      "Epoch 23/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0396 - rse: 0.2659 - corr: 0.9539\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0359 - rse: 0.2547 - corr: 0.9378\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0324 - rse: 0.2305 - corr: 0.9425\n",
      "27/38 [====================>.........] - ETA: 0s - loss: 0.0310 - rse: 0.2226 - corr: 0.9428\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.0303 - rse: 0.2178 - corr: 0.9431\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0303 - rse: 0.2177 - corr: nan - val_loss: 0.0625 - val_rse: 0.5350 - val_corr: 0.1905\n",
      "Epoch 24/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0303 - rse: 0.2188 - corr: 0.9630\n",
      " 9/38 [======>.......................] - ETA: 0s - loss: 0.0276 - rse: 0.2001 - corr: 0.9490\n",
      "18/38 [=============>................] - ETA: 0s - loss: 0.0266 - rse: 0.1925 - corr: 0.9494\n",
      "27/38 [====================>.........] - ETA: 0s - loss: 0.0262 - rse: 0.1911 - corr: 0.9493\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.0257 - rse: 0.1883 - corr: 0.9500\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0256 - rse: 0.1877 - corr: nan - val_loss: 0.0591 - val_rse: 0.5108 - val_corr: 0.1886\n",
      "Epoch 25/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0236 - rse: 0.1687 - corr: 0.9542\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0256 - rse: 0.1879 - corr: 0.9503\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0246 - rse: 0.1806 - corr: 0.9530\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0248 - rse: 0.1829 - corr: 0.9518\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0248 - rse: 0.1849 - corr: nan - val_loss: 0.0561 - val_rse: 0.4840 - val_corr: 0.1897\n",
      "Epoch 26/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0226 - rse: 0.1657 - corr: 0.9659\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0250 - rse: 0.1845 - corr: 0.9479\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0244 - rse: 0.1797 - corr: 0.9496\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 0.0241 - rse: 0.1775 - corr: 0.9514\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0240 - rse: 0.1764 - corr: nan   \n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0240 - rse: 0.1764 - corr: nan - val_loss: 0.0530 - val_rse: 0.4670 - val_corr: 0.1894\n",
      "Epoch 27/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0277 - rse: 0.1926 - corr: 0.9547\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0250 - rse: 0.1821 - corr: 0.9567\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0250 - rse: 0.1827 - corr: 0.9527\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0249 - rse: 0.1811 - corr: 0.9538\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0249 - rse: 0.1818 - corr: nan - val_loss: 0.0566 - val_rse: 0.4873 - val_corr: 0.1894\n",
      "Epoch 28/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0264 - rse: 0.1956 - corr: 0.9618\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0244 - rse: 0.1779 - corr: 0.9561\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0246 - rse: 0.1809 - corr: 0.9516\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0240 - rse: 0.1779 - corr: 0.9522\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0237 - rse: 0.1758 - corr: nan - val_loss: 0.0484 - val_rse: 0.4262 - val_corr: 0.1877\n",
      "Epoch 29/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0224 - rse: 0.1737 - corr: 0.9567\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0227 - rse: 0.1688 - corr: 0.9511\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0228 - rse: 0.1695 - corr: 0.9549\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0229 - rse: 0.1701 - corr: 0.9530\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0231 - rse: 0.1748 - corr: nan   \n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0231 - rse: 0.1748 - corr: nan - val_loss: 0.0470 - val_rse: 0.4162 - val_corr: 0.1882\n",
      "Epoch 30/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0244 - rse: 0.1848 - corr: 0.9534\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0243 - rse: 0.1800 - corr: 0.9536\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0239 - rse: 0.1778 - corr: 0.9519\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0231 - rse: 0.1714 - corr: 0.9541\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0228 - rse: 0.1698 - corr: nan - val_loss: 0.0496 - val_rse: 0.4347 - val_corr: 0.1934\n",
      "Epoch 31/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0242 - rse: 0.1761 - corr: 0.9551\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0223 - rse: 0.1634 - corr: 0.9583\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0224 - rse: 0.1653 - corr: 0.9565\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 0.0228 - rse: 0.1697 - corr: 0.9545\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0226 - rse: 0.1679 - corr: 0.9548\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0227 - rse: 0.1706 - corr: nan - val_loss: 0.0471 - val_rse: 0.4168 - val_corr: 0.1929\n",
      "Epoch 32/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0232 - rse: 0.1798 - corr: 0.9371\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0242 - rse: 0.1805 - corr: 0.9508\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0232 - rse: 0.1736 - corr: 0.9523\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0224 - rse: 0.1669 - corr: 0.9541\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0222 - rse: 0.1672 - corr: nan   \n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0222 - rse: 0.1672 - corr: nan - val_loss: 0.0440 - val_rse: 0.3929 - val_corr: 0.1943\n",
      "Epoch 33/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0218 - rse: 0.1507 - corr: 0.9626\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0247 - rse: 0.1794 - corr: 0.9566\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0247 - rse: 0.1798 - corr: 0.9543\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0240 - rse: 0.1768 - corr: 0.9544\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0235 - rse: 0.1738 - corr: nan - val_loss: 0.0443 - val_rse: 0.3914 - val_corr: 0.1902\n",
      "Epoch 34/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0209 - rse: 0.1617 - corr: 0.9516\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0223 - rse: 0.1651 - corr: 0.9578\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0220 - rse: 0.1623 - corr: 0.9582\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 0.0222 - rse: 0.1658 - corr: 0.9544\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.0218 - rse: 0.1631 - corr: 0.9560\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0218 - rse: 0.1622 - corr: nan - val_loss: 0.0408 - val_rse: 0.3660 - val_corr: 0.1929\n",
      "Epoch 35/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0218 - rse: 0.1634 - corr: 0.9684\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0214 - rse: 0.1599 - corr: 0.9615\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0219 - rse: 0.1638 - corr: 0.9579\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0218 - rse: 0.1622 - corr: 0.9576\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0218 - rse: 0.1627 - corr: nan - val_loss: 0.0415 - val_rse: 0.3677 - val_corr: 0.1914\n",
      "Epoch 36/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0195 - rse: 0.1430 - corr: 0.9599\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0221 - rse: 0.1657 - corr: 0.9512\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0221 - rse: 0.1658 - corr: 0.9540\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0218 - rse: 0.1624 - corr: 0.9556\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0217 - rse: 0.1651 - corr: nan - val_loss: 0.0425 - val_rse: 0.3750 - val_corr: 0.1897\n",
      "Epoch 37/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0213 - rse: 0.1603 - corr: 0.9627\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0234 - rse: 0.1748 - corr: 0.9494\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0222 - rse: 0.1666 - corr: 0.9538\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0215 - rse: 0.1613 - corr: 0.9570\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0214 - rse: 0.1628 - corr: nan   \n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0214 - rse: 0.1628 - corr: nan - val_loss: 0.0384 - val_rse: 0.3438 - val_corr: 0.1914\n",
      "Epoch 38/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0219 - rse: 0.1553 - corr: 0.9521\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0210 - rse: 0.1583 - corr: 0.9569\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0211 - rse: 0.1600 - corr: 0.9535\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0207 - rse: 0.1567 - corr: 0.9564\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0208 - rse: 0.1612 - corr: nan - val_loss: 0.0363 - val_rse: 0.3275 - val_corr: 0.1923\n",
      "Epoch 39/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0225 - rse: 0.1759 - corr: 0.9642\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0206 - rse: 0.1571 - corr: 0.9545\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0204 - rse: 0.1549 - corr: 0.9551\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0205 - rse: 0.1558 - corr: 0.9566\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0206 - rse: 0.1571 - corr: nan - val_loss: 0.0375 - val_rse: 0.3361 - val_corr: 0.1969\n",
      "Epoch 40/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0226 - rse: 0.1659 - corr: 0.9664\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0210 - rse: 0.1562 - corr: 0.9600\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0214 - rse: 0.1615 - corr: 0.9562\n",
      "28/38 [=====================>........] - ETA: 0s - loss: 0.0210 - rse: 0.1577 - corr: 0.9574\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0207 - rse: 0.1562 - corr: nan   \n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0207 - rse: 0.1562 - corr: nan - val_loss: 0.0365 - val_rse: 0.3279 - val_corr: 0.1931\n",
      "Epoch 41/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0210 - rse: 0.1581 - corr: 0.9626\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0210 - rse: 0.1586 - corr: 0.9614\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0206 - rse: 0.1557 - corr: 0.9604\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0205 - rse: 0.1543 - corr: 0.9604\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0203 - rse: 0.1523 - corr: nan - val_loss: 0.0396 - val_rse: 0.3510 - val_corr: 0.1972\n",
      "Epoch 42/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0250 - rse: 0.1787 - corr: 0.9515\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0206 - rse: 0.1543 - corr: 0.9612\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0204 - rse: 0.1518 - corr: 0.9613\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0207 - rse: 0.1557 - corr: 0.9584\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0207 - rse: 0.1557 - corr: nan - val_loss: 0.0345 - val_rse: 0.3124 - val_corr: 0.1945\n",
      "Epoch 43/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0212 - rse: 0.1586 - corr: 0.9513\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0205 - rse: 0.1521 - corr: 0.9598\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0206 - rse: 0.1555 - corr: 0.9560\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0203 - rse: 0.1537 - corr: 0.9585\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0203 - rse: 0.1537 - corr: nan - val_loss: 0.0351 - val_rse: 0.3166 - val_corr: 0.1991\n",
      "Epoch 44/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0174 - rse: 0.1258 - corr: 0.9627\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0202 - rse: 0.1520 - corr: 0.9590\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0206 - rse: 0.1544 - corr: 0.9571\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0202 - rse: 0.1522 - corr: 0.9580\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0201 - rse: 0.1515 - corr: nan - val_loss: 0.0343 - val_rse: 0.3098 - val_corr: 0.1976\n",
      "Epoch 45/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0194 - rse: 0.1502 - corr: 0.9603\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0210 - rse: 0.1589 - corr: 0.9576\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0202 - rse: 0.1552 - corr: 0.9581\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0200 - rse: 0.1524 - corr: 0.9588\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0200 - rse: 0.1516 - corr: nan - val_loss: 0.0324 - val_rse: 0.2964 - val_corr: 0.1998\n",
      "Epoch 46/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0208 - rse: 0.1642 - corr: 0.9626\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0191 - rse: 0.1437 - corr: 0.9634\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0198 - rse: 0.1497 - corr: 0.9602\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0196 - rse: 0.1475 - corr: 0.9609\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0197 - rse: 0.1477 - corr: nan - val_loss: 0.0324 - val_rse: 0.2948 - val_corr: 0.2008\n",
      "Epoch 47/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0183 - rse: 0.1376 - corr: 0.9651\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0199 - rse: 0.1519 - corr: 0.9590\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0196 - rse: 0.1493 - corr: 0.9594\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0195 - rse: 0.1493 - corr: 0.9584\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0195 - rse: 0.1511 - corr: nan - val_loss: 0.0317 - val_rse: 0.2898 - val_corr: 0.2071\n",
      "Epoch 48/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0178 - rse: 0.1342 - corr: 0.9605\n",
      "12/38 [========>.....................] - ETA: 0s - loss: 0.0189 - rse: 0.1409 - corr: 0.9628\n",
      "22/38 [================>.............] - ETA: 0s - loss: 0.0197 - rse: 0.1486 - corr: 0.9596\n",
      "32/38 [========================>.....] - ETA: 0s - loss: 0.0195 - rse: 0.1472 - corr: 0.9607\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0197 - rse: 0.1491 - corr: nan - val_loss: 0.0343 - val_rse: 0.3108 - val_corr: 0.2051\n",
      "Epoch 49/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0161 - rse: 0.1219 - corr: 0.9727\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0200 - rse: 0.1479 - corr: 0.9606\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0198 - rse: 0.1472 - corr: 0.9600\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0198 - rse: 0.1488 - corr: 0.9600\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0195 - rse: 0.1480 - corr: nan - val_loss: 0.0307 - val_rse: 0.2815 - val_corr: 0.2045\n",
      "Epoch 50/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0173 - rse: 0.1324 - corr: 0.9653\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0190 - rse: 0.1438 - corr: 0.9626\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0199 - rse: 0.1493 - corr: 0.9609\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0195 - rse: 0.1476 - corr: 0.9609\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0193 - rse: 0.1454 - corr: nan - val_loss: 0.0310 - val_rse: 0.2843 - val_corr: 0.2066\n",
      "Epoch 51/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0216 - rse: 0.1577 - corr: 0.9594\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0190 - rse: 0.1426 - corr: 0.9640\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0195 - rse: 0.1468 - corr: 0.9624\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0195 - rse: 0.1481 - corr: 0.9597\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0193 - rse: 0.1465 - corr: nan - val_loss: 0.0295 - val_rse: 0.2717 - val_corr: 0.2056\n",
      "Epoch 52/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0171 - rse: 0.1262 - corr: 0.9659\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0192 - rse: 0.1422 - corr: 0.9651\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0191 - rse: 0.1444 - corr: 0.9638\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0195 - rse: 0.1476 - corr: 0.9624\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0192 - rse: 0.1454 - corr: nan - val_loss: 0.0299 - val_rse: 0.2745 - val_corr: 0.2081\n",
      "Epoch 53/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0214 - rse: 0.1552 - corr: 0.9588\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0195 - rse: 0.1474 - corr: 0.9586\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0190 - rse: 0.1447 - corr: 0.9624\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0189 - rse: 0.1443 - corr: 0.9614\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0190 - rse: 0.1421 - corr: nan - val_loss: 0.0289 - val_rse: 0.2666 - val_corr: 0.2146\n",
      "Epoch 54/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0177 - rse: 0.1337 - corr: 0.9500\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0177 - rse: 0.1325 - corr: 0.9648\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0184 - rse: 0.1377 - corr: 0.9647\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0187 - rse: 0.1409 - corr: 0.9623\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0186 - rse: 0.1405 - corr: nan - val_loss: 0.0295 - val_rse: 0.2712 - val_corr: 0.2159\n",
      "Epoch 55/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0206 - rse: 0.1664 - corr: 0.9527\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0188 - rse: 0.1452 - corr: 0.9577\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0185 - rse: 0.1411 - corr: 0.9606\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0188 - rse: 0.1424 - corr: 0.9622\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0187 - rse: 0.1407 - corr: nan - val_loss: 0.0312 - val_rse: 0.2855 - val_corr: 0.2096\n",
      "Epoch 56/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0165 - rse: 0.1250 - corr: 0.9718\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0190 - rse: 0.1429 - corr: 0.9647\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0188 - rse: 0.1419 - corr: 0.9639\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0185 - rse: 0.1389 - corr: 0.9645\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0187 - rse: 0.1415 - corr: nan - val_loss: 0.0288 - val_rse: 0.2659 - val_corr: 0.2190\n",
      "Epoch 57/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0176 - rse: 0.1331 - corr: 0.9624\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0186 - rse: 0.1417 - corr: 0.9646\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0183 - rse: 0.1390 - corr: 0.9651\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0183 - rse: 0.1385 - corr: 0.9647\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0184 - rse: 0.1389 - corr: nan - val_loss: 0.0275 - val_rse: 0.2551 - val_corr: 0.2164\n",
      "Epoch 58/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0186 - rse: 0.1398 - corr: 0.9701\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0186 - rse: 0.1403 - corr: 0.9628\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0186 - rse: 0.1410 - corr: 0.9633\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0183 - rse: 0.1393 - corr: 0.9636\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0182 - rse: 0.1427 - corr: nan - val_loss: 0.0290 - val_rse: 0.2678 - val_corr: 0.2206\n",
      "Epoch 59/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0184 - rse: 0.1370 - corr: 0.9631\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0197 - rse: 0.1466 - corr: 0.9641\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0186 - rse: 0.1397 - corr: 0.9644\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0184 - rse: 0.1383 - corr: 0.9647\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0185 - rse: 0.1410 - corr: nan - val_loss: 0.0270 - val_rse: 0.2515 - val_corr: 0.2284\n",
      "Epoch 60/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0160 - rse: 0.1164 - corr: 0.9718\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0179 - rse: 0.1338 - corr: 0.9652\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0178 - rse: 0.1340 - corr: 0.9654\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0179 - rse: 0.1364 - corr: 0.9646\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0179 - rse: 0.1353 - corr: nan - val_loss: 0.0268 - val_rse: 0.2493 - val_corr: 0.2344\n",
      "Epoch 61/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0173 - rse: 0.1311 - corr: 0.9641\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0181 - rse: 0.1334 - corr: 0.9666\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0183 - rse: 0.1362 - corr: 0.9663\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0182 - rse: 0.1356 - corr: 0.9660\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0184 - rse: 0.1414 - corr: nan - val_loss: 0.0279 - val_rse: 0.2581 - val_corr: 0.2198\n",
      "Epoch 62/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0167 - rse: 0.1261 - corr: 0.9656\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0189 - rse: 0.1442 - corr: 0.9633\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0181 - rse: 0.1367 - corr: 0.9657\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0178 - rse: 0.1344 - corr: 0.9659\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0178 - rse: 0.1358 - corr: nan - val_loss: 0.0269 - val_rse: 0.2504 - val_corr: 0.2303\n",
      "Epoch 63/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0160 - rse: 0.1223 - corr: 0.9761\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0177 - rse: 0.1352 - corr: 0.9670\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0180 - rse: 0.1347 - corr: 0.9689\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0178 - rse: 0.1346 - corr: 0.9665\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0179 - rse: 0.1364 - corr: nan - val_loss: 0.0272 - val_rse: 0.2524 - val_corr: 0.2238\n",
      "Epoch 64/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0148 - rse: 0.1106 - corr: 0.9746\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0185 - rse: 0.1416 - corr: 0.9630\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0181 - rse: 0.1364 - corr: 0.9662\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0179 - rse: 0.1357 - corr: 0.9656\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0180 - rse: 0.1353 - corr: nan - val_loss: 0.0269 - val_rse: 0.2506 - val_corr: 0.2303\n",
      "Epoch 65/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0190 - rse: 0.1424 - corr: 0.9634\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0182 - rse: 0.1359 - corr: 0.9634\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0180 - rse: 0.1362 - corr: 0.9647\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0181 - rse: 0.1376 - corr: 0.9641\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0182 - rse: 0.1377 - corr: nan - val_loss: 0.0264 - val_rse: 0.2460 - val_corr: 0.2298\n",
      "Epoch 66/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0177 - rse: 0.1358 - corr: 0.9618\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0179 - rse: 0.1369 - corr: 0.9635\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0175 - rse: 0.1331 - corr: 0.9654\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0175 - rse: 0.1338 - corr: 0.9666\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0176 - rse: 0.1360 - corr: nan - val_loss: 0.0251 - val_rse: 0.2339 - val_corr: 0.2366\n",
      "Epoch 67/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0172 - rse: 0.1221 - corr: 0.9725\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0188 - rse: 0.1428 - corr: 0.9635\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0179 - rse: 0.1369 - corr: 0.9636\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0178 - rse: 0.1355 - corr: 0.9653\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0180 - rse: 0.1431 - corr: nan - val_loss: 0.0260 - val_rse: 0.2427 - val_corr: 0.2328\n",
      "Epoch 68/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0172 - rse: 0.1299 - corr: 0.9758\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0181 - rse: 0.1368 - corr: 0.9661\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0192 - rse: 0.1438 - corr: 0.9649\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0188 - rse: 0.1408 - corr: 0.9658\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0187 - rse: 0.1425 - corr: nan - val_loss: 0.0249 - val_rse: 0.2345 - val_corr: 0.2217\n",
      "Epoch 69/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0166 - rse: 0.1361 - corr: 0.9663\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0179 - rse: 0.1358 - corr: 0.9676\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0181 - rse: 0.1363 - corr: 0.9659\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0180 - rse: 0.1363 - corr: 0.9652\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0179 - rse: 0.1351 - corr: nan - val_loss: 0.0252 - val_rse: 0.2360 - val_corr: 0.2335\n",
      "Epoch 70/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0224 - rse: 0.1728 - corr: 0.9533\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0184 - rse: 0.1392 - corr: 0.9648\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0186 - rse: 0.1413 - corr: 0.9643\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0183 - rse: 0.1387 - corr: 0.9645\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0181 - rse: 0.1368 - corr: nan - val_loss: 0.0245 - val_rse: 0.2301 - val_corr: 0.2421\n",
      "Epoch 71/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0192 - rse: 0.1443 - corr: 0.9664\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0184 - rse: 0.1421 - corr: 0.9623\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0177 - rse: 0.1350 - corr: 0.9669\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0175 - rse: 0.1327 - corr: 0.9668\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0174 - rse: 0.1364 - corr: nan - val_loss: 0.0241 - val_rse: 0.2266 - val_corr: 0.2431\n",
      "Epoch 72/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0157 - rse: 0.1140 - corr: 0.9773\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0175 - rse: 0.1327 - corr: 0.9654\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0176 - rse: 0.1337 - corr: 0.9661\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0172 - rse: 0.1304 - corr: 0.9677\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0169 - rse: 0.1283 - corr: nan - val_loss: 0.0249 - val_rse: 0.2335 - val_corr: 0.2460\n",
      "Epoch 73/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0162 - rse: 0.1200 - corr: 0.9666\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0166 - rse: 0.1263 - corr: 0.9705\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0172 - rse: 0.1315 - corr: 0.9682\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0173 - rse: 0.1314 - corr: 0.9678\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.0172 - rse: 0.1299 - corr: nan - val_loss: 0.0241 - val_rse: 0.2266 - val_corr: 0.2495\n",
      "Epoch 74/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0163 - rse: 0.1250 - corr: 0.9787\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0173 - rse: 0.1320 - corr: 0.9688\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0167 - rse: 0.1270 - corr: 0.9712\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0166 - rse: 0.1261 - corr: 0.9700\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0169 - rse: 0.1279 - corr: nan   \n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0169 - rse: 0.1279 - corr: nan - val_loss: 0.0237 - val_rse: 0.2223 - val_corr: 0.2539\n",
      "Epoch 75/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0168 - rse: 0.1426 - corr: 0.9611\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0167 - rse: 0.1291 - corr: 0.9678\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0169 - rse: 0.1296 - corr: 0.9685\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0171 - rse: 0.1304 - corr: 0.9679\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0171 - rse: 0.1294 - corr: nan - val_loss: 0.0255 - val_rse: 0.2382 - val_corr: 0.2569\n",
      "Epoch 76/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0175 - rse: 0.1288 - corr: 0.9683\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0171 - rse: 0.1280 - corr: 0.9725\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0171 - rse: 0.1314 - corr: 0.9690\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0171 - rse: 0.1309 - corr: 0.9679\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0171 - rse: 0.1287 - corr: nan - val_loss: 0.0237 - val_rse: 0.2238 - val_corr: 0.2501\n",
      "Epoch 77/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0187 - rse: 0.1425 - corr: 0.9735\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0173 - rse: 0.1309 - corr: 0.9684\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0171 - rse: 0.1301 - corr: 0.9689\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0165 - rse: 0.1252 - corr: 0.9712\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0165 - rse: 0.1246 - corr: nan - val_loss: 0.0234 - val_rse: 0.2206 - val_corr: 0.2690\n",
      "Epoch 78/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0149 - rse: 0.1177 - corr: 0.9696\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0167 - rse: 0.1281 - corr: 0.9693\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0168 - rse: 0.1274 - corr: 0.9700\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0166 - rse: 0.1261 - corr: 0.9700\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0166 - rse: 0.1276 - corr: nan - val_loss: 0.0235 - val_rse: 0.2219 - val_corr: 0.2516\n",
      "Epoch 79/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0176 - rse: 0.1353 - corr: 0.9690\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0168 - rse: 0.1250 - corr: 0.9723\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0168 - rse: 0.1270 - corr: 0.9705\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0169 - rse: 0.1283 - corr: 0.9686\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0167 - rse: 0.1253 - corr: nan - val_loss: 0.0231 - val_rse: 0.2179 - val_corr: 0.2718\n",
      "Epoch 80/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0165 - rse: 0.1276 - corr: 0.9688\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0177 - rse: 0.1343 - corr: 0.9686\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0173 - rse: 0.1300 - corr: 0.9689\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0169 - rse: 0.1274 - corr: 0.9696\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0169 - rse: 0.1286 - corr: nan - val_loss: 0.0233 - val_rse: 0.2202 - val_corr: 0.2771\n",
      "Epoch 81/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0158 - rse: 0.1269 - corr: 0.9715\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0173 - rse: 0.1329 - corr: 0.9670\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0168 - rse: 0.1277 - corr: 0.9697\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0166 - rse: 0.1260 - corr: 0.9704\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0166 - rse: 0.1257 - corr: nan - val_loss: 0.0231 - val_rse: 0.2185 - val_corr: 0.2785\n",
      "Epoch 82/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0160 - rse: 0.1175 - corr: 0.9778\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0169 - rse: 0.1294 - corr: 0.9686\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0168 - rse: 0.1291 - corr: 0.9694\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0170 - rse: 0.1291 - corr: 0.9694\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0169 - rse: 0.1317 - corr: nan - val_loss: 0.0236 - val_rse: 0.2217 - val_corr: 0.2682\n",
      "Epoch 83/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0190 - rse: 0.1395 - corr: 0.9602\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0174 - rse: 0.1301 - corr: 0.9697\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0165 - rse: 0.1242 - corr: 0.9716\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0163 - rse: 0.1234 - corr: 0.9719\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0165 - rse: 0.1251 - corr: nan - val_loss: 0.0228 - val_rse: 0.2158 - val_corr: 0.2731\n",
      "Epoch 84/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0167 - rse: 0.1177 - corr: 0.9779\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0162 - rse: 0.1205 - corr: 0.9746\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0164 - rse: 0.1237 - corr: 0.9715\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0167 - rse: 0.1261 - corr: 0.9707\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0167 - rse: 0.1260 - corr: nan - val_loss: 0.0229 - val_rse: 0.2169 - val_corr: 0.2580\n",
      "Epoch 85/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0157 - rse: 0.1095 - corr: 0.9719\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0163 - rse: 0.1220 - corr: 0.9686\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0169 - rse: 0.1287 - corr: 0.9655\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0168 - rse: 0.1281 - corr: 0.9666\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0166 - rse: 0.1252 - corr: nan - val_loss: 0.0238 - val_rse: 0.2242 - val_corr: 0.2628\n",
      "Epoch 86/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0145 - rse: 0.1079 - corr: 0.9779\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0166 - rse: 0.1284 - corr: 0.9659\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0162 - rse: 0.1240 - corr: 0.9693\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0166 - rse: 0.1263 - corr: 0.9681\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0166 - rse: 0.1264 - corr: nan - val_loss: 0.0225 - val_rse: 0.2128 - val_corr: 0.2663\n",
      "Epoch 87/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0172 - rse: 0.1351 - corr: 0.9670\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0167 - rse: 0.1274 - corr: 0.9679\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0160 - rse: 0.1211 - corr: 0.9713\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0159 - rse: 0.1206 - corr: 0.9717\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0160 - rse: 0.1237 - corr: nan - val_loss: 0.0223 - val_rse: 0.2118 - val_corr: 0.2767\n",
      "Epoch 88/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0139 - rse: 0.1049 - corr: 0.9725\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0161 - rse: 0.1251 - corr: 0.9666\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0165 - rse: 0.1274 - corr: 0.9654\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0166 - rse: 0.1273 - corr: 0.9667\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0166 - rse: 0.1358 - corr: nan - val_loss: 0.0221 - val_rse: 0.2087 - val_corr: 0.2802\n",
      "Epoch 89/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0169 - rse: 0.1345 - corr: 0.9606\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0176 - rse: 0.1320 - corr: 0.9719\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0168 - rse: 0.1260 - corr: 0.9729\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0171 - rse: 0.1288 - corr: 0.9707\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0171 - rse: 0.1285 - corr: nan - val_loss: 0.0224 - val_rse: 0.2124 - val_corr: 0.2709\n",
      "Epoch 90/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0136 - rse: 0.1022 - corr: 0.9759\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0161 - rse: 0.1201 - corr: 0.9737\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0159 - rse: 0.1206 - corr: 0.9726\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0162 - rse: 0.1239 - corr: 0.9702\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0163 - rse: 0.1246 - corr: nan - val_loss: 0.0224 - val_rse: 0.2118 - val_corr: 0.2735\n",
      "Epoch 91/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0162 - rse: 0.1231 - corr: 0.9742\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0169 - rse: 0.1274 - corr: 0.9707\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0163 - rse: 0.1227 - corr: 0.9717\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0162 - rse: 0.1224 - corr: 0.9706\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0159 - rse: 0.1220 - corr: nan - val_loss: 0.0220 - val_rse: 0.2075 - val_corr: 0.2802\n",
      "Epoch 92/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0155 - rse: 0.1192 - corr: 0.9653\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0164 - rse: 0.1217 - corr: 0.9700\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0161 - rse: 0.1206 - corr: 0.9706\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0161 - rse: 0.1225 - corr: 0.9696\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0162 - rse: 0.1229 - corr: nan - val_loss: 0.0223 - val_rse: 0.2112 - val_corr: 0.2843\n",
      "Epoch 93/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0184 - rse: 0.1401 - corr: 0.9674\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0166 - rse: 0.1281 - corr: 0.9700\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0164 - rse: 0.1259 - corr: 0.9711\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0162 - rse: 0.1232 - corr: 0.9714\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0161 - rse: 0.1229 - corr: nan - val_loss: 0.0228 - val_rse: 0.2156 - val_corr: 0.2832\n",
      "Epoch 94/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0161 - rse: 0.1274 - corr: 0.9723\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0154 - rse: 0.1178 - corr: 0.9724\n",
      "21/38 [===============>..............] - ETA: 0s - loss: 0.0156 - rse: 0.1175 - corr: 0.9742\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0159 - rse: 0.1199 - corr: 0.9733\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0159 - rse: 0.1196 - corr: nan - val_loss: 0.0217 - val_rse: 0.2060 - val_corr: 0.2841\n",
      "Epoch 95/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0154 - rse: 0.1185 - corr: 0.9772\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0162 - rse: 0.1233 - corr: 0.9714\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0162 - rse: 0.1232 - corr: 0.9721\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0161 - rse: 0.1216 - corr: 0.9727\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0159 - rse: 0.1214 - corr: nan - val_loss: 0.0213 - val_rse: 0.2019 - val_corr: 0.3089\n",
      "Epoch 96/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0137 - rse: 0.0965 - corr: 0.9800\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0159 - rse: 0.1173 - corr: 0.9751\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0154 - rse: 0.1147 - corr: 0.9753\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0154 - rse: 0.1155 - corr: 0.9747\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0154 - rse: 0.1166 - corr: nan - val_loss: 0.0218 - val_rse: 0.2066 - val_corr: 0.2961\n",
      "Epoch 97/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0154 - rse: 0.1174 - corr: 0.9730\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0146 - rse: 0.1102 - corr: 0.9774\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0150 - rse: 0.1130 - corr: 0.9761\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0152 - rse: 0.1159 - corr: 0.9749\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0152 - rse: 0.1159 - corr: nan - val_loss: 0.0222 - val_rse: 0.2051 - val_corr: 0.3324\n",
      "Epoch 98/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0237 - rse: 0.1713 - corr: 0.9737\n",
      "10/38 [======>.......................] - ETA: 0s - loss: 0.0168 - rse: 0.1242 - corr: 0.9749\n",
      "19/38 [==============>...............] - ETA: 0s - loss: 0.0168 - rse: 0.1269 - corr: 0.9712\n",
      "29/38 [=====================>........] - ETA: 0s - loss: 0.0167 - rse: 0.1264 - corr: 0.9712\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0163 - rse: 0.1238 - corr: nan   \n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0163 - rse: 0.1238 - corr: nan - val_loss: 0.0218 - val_rse: 0.2027 - val_corr: 0.3252\n",
      "Epoch 99/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0192 - rse: 0.1397 - corr: 0.9783\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0165 - rse: 0.1224 - corr: 0.9750\n",
      "20/38 [==============>...............] - ETA: 0s - loss: 0.0162 - rse: 0.1222 - corr: 0.9729\n",
      "30/38 [======================>.......] - ETA: 0s - loss: 0.0165 - rse: 0.1248 - corr: 0.9716\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0164 - rse: 0.1271 - corr: nan - val_loss: 0.0215 - val_rse: 0.2030 - val_corr: 0.2895\n",
      "Epoch 100/100\n",
      "\n",
      " 1/38 [..............................] - ETA: 0s - loss: 0.0159 - rse: 0.1199 - corr: 0.9606\n",
      "11/38 [=======>......................] - ETA: 0s - loss: 0.0165 - rse: 0.1266 - corr: 0.9658\n",
      "22/38 [================>.............] - ETA: 0s - loss: 0.0162 - rse: 0.1232 - corr: 0.9684\n",
      "31/38 [=======================>......] - ETA: 0s - loss: 0.0161 - rse: 0.1240 - corr: 0.9680\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0160 - rse: 0.1224 - corr: nan - val_loss: 0.0214 - val_rse: 0.2021 - val_corr: 0.2926\n",
      "training now...\n",
      "Figure(1600x1000)\n",
      "model saved...\n",
      "\n",
      "model saved\n",
      "Outputs can be found at: LSTNet/save/large_portfolio_horizon1_window7_skip7\n"
     ]
    }
   ],
   "source": [
    "lstnet_iterated.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 743ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "forecast=lstnet_iterated.get_forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194.071411</td>\n",
       "      <td>125.847145</td>\n",
       "      <td>134.358444</td>\n",
       "      <td>345.735687</td>\n",
       "      <td>153.135803</td>\n",
       "      <td>244.960190</td>\n",
       "      <td>162.820389</td>\n",
       "      <td>150.208755</td>\n",
       "      <td>102.269943</td>\n",
       "      <td>14.121084</td>\n",
       "      <td>...</td>\n",
       "      <td>185.200714</td>\n",
       "      <td>87.612648</td>\n",
       "      <td>552.511475</td>\n",
       "      <td>99.706757</td>\n",
       "      <td>902.465698</td>\n",
       "      <td>143.195236</td>\n",
       "      <td>208.482407</td>\n",
       "      <td>73.994469</td>\n",
       "      <td>182.703857</td>\n",
       "      <td>45.711899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194.638016</td>\n",
       "      <td>126.971901</td>\n",
       "      <td>135.046936</td>\n",
       "      <td>354.853821</td>\n",
       "      <td>153.625488</td>\n",
       "      <td>245.671051</td>\n",
       "      <td>158.124191</td>\n",
       "      <td>148.793228</td>\n",
       "      <td>101.351631</td>\n",
       "      <td>13.822315</td>\n",
       "      <td>...</td>\n",
       "      <td>185.010757</td>\n",
       "      <td>86.974686</td>\n",
       "      <td>556.366211</td>\n",
       "      <td>99.637421</td>\n",
       "      <td>910.549011</td>\n",
       "      <td>147.304016</td>\n",
       "      <td>207.261978</td>\n",
       "      <td>72.986893</td>\n",
       "      <td>183.773956</td>\n",
       "      <td>45.877590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195.604523</td>\n",
       "      <td>124.765602</td>\n",
       "      <td>134.778625</td>\n",
       "      <td>361.916748</td>\n",
       "      <td>154.775803</td>\n",
       "      <td>243.557465</td>\n",
       "      <td>159.978775</td>\n",
       "      <td>149.918945</td>\n",
       "      <td>102.195305</td>\n",
       "      <td>14.399155</td>\n",
       "      <td>...</td>\n",
       "      <td>186.533737</td>\n",
       "      <td>87.051430</td>\n",
       "      <td>559.325562</td>\n",
       "      <td>99.451187</td>\n",
       "      <td>904.900452</td>\n",
       "      <td>144.661819</td>\n",
       "      <td>206.378510</td>\n",
       "      <td>72.742111</td>\n",
       "      <td>184.396133</td>\n",
       "      <td>46.014328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196.449768</td>\n",
       "      <td>122.343315</td>\n",
       "      <td>134.495346</td>\n",
       "      <td>357.513397</td>\n",
       "      <td>156.202576</td>\n",
       "      <td>242.698853</td>\n",
       "      <td>164.594406</td>\n",
       "      <td>151.216263</td>\n",
       "      <td>103.817947</td>\n",
       "      <td>14.744738</td>\n",
       "      <td>...</td>\n",
       "      <td>188.417633</td>\n",
       "      <td>88.695679</td>\n",
       "      <td>560.644897</td>\n",
       "      <td>100.184402</td>\n",
       "      <td>903.905396</td>\n",
       "      <td>140.874863</td>\n",
       "      <td>208.185638</td>\n",
       "      <td>73.279297</td>\n",
       "      <td>182.792557</td>\n",
       "      <td>46.100967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195.790924</td>\n",
       "      <td>121.463997</td>\n",
       "      <td>132.152954</td>\n",
       "      <td>351.117645</td>\n",
       "      <td>157.112625</td>\n",
       "      <td>241.508972</td>\n",
       "      <td>171.154663</td>\n",
       "      <td>153.143753</td>\n",
       "      <td>105.305466</td>\n",
       "      <td>14.860121</td>\n",
       "      <td>...</td>\n",
       "      <td>188.483078</td>\n",
       "      <td>90.336082</td>\n",
       "      <td>563.760498</td>\n",
       "      <td>99.184296</td>\n",
       "      <td>909.942261</td>\n",
       "      <td>135.684906</td>\n",
       "      <td>210.266663</td>\n",
       "      <td>75.446655</td>\n",
       "      <td>184.149750</td>\n",
       "      <td>46.041008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>195.254883</td>\n",
       "      <td>123.670815</td>\n",
       "      <td>132.410080</td>\n",
       "      <td>347.891754</td>\n",
       "      <td>155.955170</td>\n",
       "      <td>243.139771</td>\n",
       "      <td>171.225525</td>\n",
       "      <td>153.566788</td>\n",
       "      <td>104.887054</td>\n",
       "      <td>14.725681</td>\n",
       "      <td>...</td>\n",
       "      <td>187.436630</td>\n",
       "      <td>89.748123</td>\n",
       "      <td>561.577759</td>\n",
       "      <td>99.010361</td>\n",
       "      <td>909.837158</td>\n",
       "      <td>136.844620</td>\n",
       "      <td>210.735809</td>\n",
       "      <td>76.172478</td>\n",
       "      <td>185.485931</td>\n",
       "      <td>46.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>195.755188</td>\n",
       "      <td>127.248161</td>\n",
       "      <td>135.360306</td>\n",
       "      <td>350.569336</td>\n",
       "      <td>154.600571</td>\n",
       "      <td>247.102234</td>\n",
       "      <td>163.695709</td>\n",
       "      <td>151.376221</td>\n",
       "      <td>103.015671</td>\n",
       "      <td>14.164936</td>\n",
       "      <td>...</td>\n",
       "      <td>186.616989</td>\n",
       "      <td>88.264984</td>\n",
       "      <td>558.613403</td>\n",
       "      <td>100.326736</td>\n",
       "      <td>912.922607</td>\n",
       "      <td>144.933105</td>\n",
       "      <td>210.096237</td>\n",
       "      <td>74.650093</td>\n",
       "      <td>184.939667</td>\n",
       "      <td>46.129829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>196.581573</td>\n",
       "      <td>127.930374</td>\n",
       "      <td>136.463165</td>\n",
       "      <td>359.690796</td>\n",
       "      <td>154.997375</td>\n",
       "      <td>247.689911</td>\n",
       "      <td>159.314423</td>\n",
       "      <td>150.220276</td>\n",
       "      <td>102.247192</td>\n",
       "      <td>14.041058</td>\n",
       "      <td>...</td>\n",
       "      <td>186.878464</td>\n",
       "      <td>87.536713</td>\n",
       "      <td>561.279907</td>\n",
       "      <td>100.580437</td>\n",
       "      <td>916.562622</td>\n",
       "      <td>148.641205</td>\n",
       "      <td>208.760437</td>\n",
       "      <td>73.436989</td>\n",
       "      <td>185.491257</td>\n",
       "      <td>46.310356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>197.616516</td>\n",
       "      <td>125.529594</td>\n",
       "      <td>136.186203</td>\n",
       "      <td>364.624420</td>\n",
       "      <td>156.418808</td>\n",
       "      <td>245.814545</td>\n",
       "      <td>161.579132</td>\n",
       "      <td>151.233414</td>\n",
       "      <td>103.286041</td>\n",
       "      <td>14.534239</td>\n",
       "      <td>...</td>\n",
       "      <td>188.587479</td>\n",
       "      <td>88.083084</td>\n",
       "      <td>564.464172</td>\n",
       "      <td>100.646980</td>\n",
       "      <td>913.240295</td>\n",
       "      <td>145.884857</td>\n",
       "      <td>208.509155</td>\n",
       "      <td>73.273705</td>\n",
       "      <td>185.474792</td>\n",
       "      <td>46.452160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>198.065369</td>\n",
       "      <td>122.985397</td>\n",
       "      <td>134.979446</td>\n",
       "      <td>360.081390</td>\n",
       "      <td>157.934097</td>\n",
       "      <td>244.248596</td>\n",
       "      <td>167.725082</td>\n",
       "      <td>153.063782</td>\n",
       "      <td>105.143326</td>\n",
       "      <td>14.931171</td>\n",
       "      <td>...</td>\n",
       "      <td>190.173935</td>\n",
       "      <td>89.875526</td>\n",
       "      <td>566.874023</td>\n",
       "      <td>100.719048</td>\n",
       "      <td>913.320923</td>\n",
       "      <td>140.595322</td>\n",
       "      <td>210.367340</td>\n",
       "      <td>74.422668</td>\n",
       "      <td>184.869263</td>\n",
       "      <td>46.496590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>197.454468</td>\n",
       "      <td>122.724243</td>\n",
       "      <td>133.293488</td>\n",
       "      <td>353.219177</td>\n",
       "      <td>158.334213</td>\n",
       "      <td>243.785339</td>\n",
       "      <td>173.226181</td>\n",
       "      <td>154.774292</td>\n",
       "      <td>106.300110</td>\n",
       "      <td>15.014292</td>\n",
       "      <td>...</td>\n",
       "      <td>190.077072</td>\n",
       "      <td>91.096764</td>\n",
       "      <td>568.262268</td>\n",
       "      <td>100.032974</td>\n",
       "      <td>917.134155</td>\n",
       "      <td>136.587433</td>\n",
       "      <td>212.301361</td>\n",
       "      <td>76.327782</td>\n",
       "      <td>185.975128</td>\n",
       "      <td>46.434669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>197.049774</td>\n",
       "      <td>125.488693</td>\n",
       "      <td>134.119415</td>\n",
       "      <td>350.653534</td>\n",
       "      <td>157.076019</td>\n",
       "      <td>246.158905</td>\n",
       "      <td>171.498062</td>\n",
       "      <td>154.523056</td>\n",
       "      <td>105.500549</td>\n",
       "      <td>14.715868</td>\n",
       "      <td>...</td>\n",
       "      <td>188.927994</td>\n",
       "      <td>90.357788</td>\n",
       "      <td>565.901123</td>\n",
       "      <td>100.176285</td>\n",
       "      <td>918.998352</td>\n",
       "      <td>139.532639</td>\n",
       "      <td>212.673645</td>\n",
       "      <td>76.633186</td>\n",
       "      <td>186.922577</td>\n",
       "      <td>46.424889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>197.554108</td>\n",
       "      <td>128.685013</td>\n",
       "      <td>136.679581</td>\n",
       "      <td>355.390472</td>\n",
       "      <td>155.967850</td>\n",
       "      <td>249.444977</td>\n",
       "      <td>164.291504</td>\n",
       "      <td>152.504486</td>\n",
       "      <td>103.727753</td>\n",
       "      <td>14.234570</td>\n",
       "      <td>...</td>\n",
       "      <td>188.170090</td>\n",
       "      <td>88.851952</td>\n",
       "      <td>564.123352</td>\n",
       "      <td>101.157898</td>\n",
       "      <td>922.142151</td>\n",
       "      <td>146.971985</td>\n",
       "      <td>211.683411</td>\n",
       "      <td>75.156548</td>\n",
       "      <td>186.897491</td>\n",
       "      <td>46.560822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>198.561905</td>\n",
       "      <td>128.844345</td>\n",
       "      <td>137.854309</td>\n",
       "      <td>364.209259</td>\n",
       "      <td>156.495712</td>\n",
       "      <td>249.766937</td>\n",
       "      <td>160.550888</td>\n",
       "      <td>151.590057</td>\n",
       "      <td>103.189743</td>\n",
       "      <td>14.226202</td>\n",
       "      <td>...</td>\n",
       "      <td>188.795151</td>\n",
       "      <td>88.235214</td>\n",
       "      <td>566.503784</td>\n",
       "      <td>101.570953</td>\n",
       "      <td>923.694458</td>\n",
       "      <td>150.007721</td>\n",
       "      <td>210.421265</td>\n",
       "      <td>73.903755</td>\n",
       "      <td>187.095917</td>\n",
       "      <td>46.750282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>199.543610</td>\n",
       "      <td>126.184242</td>\n",
       "      <td>137.309967</td>\n",
       "      <td>367.530060</td>\n",
       "      <td>158.120926</td>\n",
       "      <td>247.786591</td>\n",
       "      <td>163.733902</td>\n",
       "      <td>152.766876</td>\n",
       "      <td>104.482346</td>\n",
       "      <td>14.709972</td>\n",
       "      <td>...</td>\n",
       "      <td>190.609421</td>\n",
       "      <td>89.158600</td>\n",
       "      <td>570.010925</td>\n",
       "      <td>101.637138</td>\n",
       "      <td>921.609863</td>\n",
       "      <td>146.544098</td>\n",
       "      <td>210.626053</td>\n",
       "      <td>73.989029</td>\n",
       "      <td>186.887878</td>\n",
       "      <td>46.882465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5   \\\n",
       "0   194.071411  125.847145  134.358444  345.735687  153.135803  244.960190   \n",
       "1   194.638016  126.971901  135.046936  354.853821  153.625488  245.671051   \n",
       "2   195.604523  124.765602  134.778625  361.916748  154.775803  243.557465   \n",
       "3   196.449768  122.343315  134.495346  357.513397  156.202576  242.698853   \n",
       "4   195.790924  121.463997  132.152954  351.117645  157.112625  241.508972   \n",
       "5   195.254883  123.670815  132.410080  347.891754  155.955170  243.139771   \n",
       "6   195.755188  127.248161  135.360306  350.569336  154.600571  247.102234   \n",
       "7   196.581573  127.930374  136.463165  359.690796  154.997375  247.689911   \n",
       "8   197.616516  125.529594  136.186203  364.624420  156.418808  245.814545   \n",
       "9   198.065369  122.985397  134.979446  360.081390  157.934097  244.248596   \n",
       "10  197.454468  122.724243  133.293488  353.219177  158.334213  243.785339   \n",
       "11  197.049774  125.488693  134.119415  350.653534  157.076019  246.158905   \n",
       "12  197.554108  128.685013  136.679581  355.390472  155.967850  249.444977   \n",
       "13  198.561905  128.844345  137.854309  364.209259  156.495712  249.766937   \n",
       "14  199.543610  126.184242  137.309967  367.530060  158.120926  247.786591   \n",
       "\n",
       "            6           7           8          9   ...          38         39  \\\n",
       "0   162.820389  150.208755  102.269943  14.121084  ...  185.200714  87.612648   \n",
       "1   158.124191  148.793228  101.351631  13.822315  ...  185.010757  86.974686   \n",
       "2   159.978775  149.918945  102.195305  14.399155  ...  186.533737  87.051430   \n",
       "3   164.594406  151.216263  103.817947  14.744738  ...  188.417633  88.695679   \n",
       "4   171.154663  153.143753  105.305466  14.860121  ...  188.483078  90.336082   \n",
       "5   171.225525  153.566788  104.887054  14.725681  ...  187.436630  89.748123   \n",
       "6   163.695709  151.376221  103.015671  14.164936  ...  186.616989  88.264984   \n",
       "7   159.314423  150.220276  102.247192  14.041058  ...  186.878464  87.536713   \n",
       "8   161.579132  151.233414  103.286041  14.534239  ...  188.587479  88.083084   \n",
       "9   167.725082  153.063782  105.143326  14.931171  ...  190.173935  89.875526   \n",
       "10  173.226181  154.774292  106.300110  15.014292  ...  190.077072  91.096764   \n",
       "11  171.498062  154.523056  105.500549  14.715868  ...  188.927994  90.357788   \n",
       "12  164.291504  152.504486  103.727753  14.234570  ...  188.170090  88.851952   \n",
       "13  160.550888  151.590057  103.189743  14.226202  ...  188.795151  88.235214   \n",
       "14  163.733902  152.766876  104.482346  14.709972  ...  190.609421  89.158600   \n",
       "\n",
       "            40          41          42          43          44         45  \\\n",
       "0   552.511475   99.706757  902.465698  143.195236  208.482407  73.994469   \n",
       "1   556.366211   99.637421  910.549011  147.304016  207.261978  72.986893   \n",
       "2   559.325562   99.451187  904.900452  144.661819  206.378510  72.742111   \n",
       "3   560.644897  100.184402  903.905396  140.874863  208.185638  73.279297   \n",
       "4   563.760498   99.184296  909.942261  135.684906  210.266663  75.446655   \n",
       "5   561.577759   99.010361  909.837158  136.844620  210.735809  76.172478   \n",
       "6   558.613403  100.326736  912.922607  144.933105  210.096237  74.650093   \n",
       "7   561.279907  100.580437  916.562622  148.641205  208.760437  73.436989   \n",
       "8   564.464172  100.646980  913.240295  145.884857  208.509155  73.273705   \n",
       "9   566.874023  100.719048  913.320923  140.595322  210.367340  74.422668   \n",
       "10  568.262268  100.032974  917.134155  136.587433  212.301361  76.327782   \n",
       "11  565.901123  100.176285  918.998352  139.532639  212.673645  76.633186   \n",
       "12  564.123352  101.157898  922.142151  146.971985  211.683411  75.156548   \n",
       "13  566.503784  101.570953  923.694458  150.007721  210.421265  73.903755   \n",
       "14  570.010925  101.637138  921.609863  146.544098  210.626053  73.989029   \n",
       "\n",
       "            46         47  \n",
       "0   182.703857  45.711899  \n",
       "1   183.773956  45.877590  \n",
       "2   184.396133  46.014328  \n",
       "3   182.792557  46.100967  \n",
       "4   184.149750  46.041008  \n",
       "5   185.485931  46.001686  \n",
       "6   184.939667  46.129829  \n",
       "7   185.491257  46.310356  \n",
       "8   185.474792  46.452160  \n",
       "9   184.869263  46.496590  \n",
       "10  185.975128  46.434669  \n",
       "11  186.922577  46.424889  \n",
       "12  186.897491  46.560822  \n",
       "13  187.095917  46.750282  \n",
       "14  186.887878  46.882465  \n",
       "\n",
       "[15 rows x 48 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(forecast.reshape(15,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 867ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "JSON data saved to LargePortfolioLSTNet_forecast.json\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstnet_iterated.plot_lstnet_forecast(series_index=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LSTNet\\\\save\\\\large_portfolio_horizon1_window28_skip7.json'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'LSTNet\\\\save\\\\large_portfolio_horizon1_window28_skip7.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
